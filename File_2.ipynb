{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2>Hypertune XGBoost using randomizedsearchCV on avgW2V features with other features </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy\n",
    "\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics.classification import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbiMFpgRdMUJ",
    "outputId": "21c00698-7f2a-4ce4-e665-f7a2feaab6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404290 non-null object\n",
      "question2       404290 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.loc[:69999,:]\n",
    "df_test = df.loc[70000:99999,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_feats_m</th>\n",
       "      <th>q2_feats_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>70000</td>\n",
       "      <td>120726</td>\n",
       "      <td>120727</td>\n",
       "      <td>What are some cake ideas for a teenager?</td>\n",
       "      <td>What are some teenage cake ideas?</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4615742415189743, 5.592962011694908, -5.16...</td>\n",
       "      <td>[-1.6438209861516953, 2.9957278221845627, -5.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>70001</td>\n",
       "      <td>120728</td>\n",
       "      <td>120729</td>\n",
       "      <td>Is there any encryption technique that cannot ...</td>\n",
       "      <td>How long does it take for a quantum computer t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-9.322475790977478, 12.87209065258503, -7.112...</td>\n",
       "      <td>[1.2852164027281106, 12.787952169775963, -4.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>70002</td>\n",
       "      <td>120730</td>\n",
       "      <td>120731</td>\n",
       "      <td>Could Napoleon have won the Napoleonic Wars?</td>\n",
       "      <td>How could Napoleon have won in Russia?</td>\n",
       "      <td>0</td>\n",
       "      <td>[-7.683586522936821, 2.8382886052131653, 11.72...</td>\n",
       "      <td>[-7.846307143568993, 8.699695736169815, 4.4572...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>70003</td>\n",
       "      <td>120732</td>\n",
       "      <td>120733</td>\n",
       "      <td>Is there an Airbnb for car-sharing in Canada?</td>\n",
       "      <td>Is there an Airbnb for car-sharing?</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.028497308492660522, 8.290659457445145, -6....</td>\n",
       "      <td>[3.1676465570926666, 6.498601824045181, -5.305...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>70004</td>\n",
       "      <td>31392</td>\n",
       "      <td>120734</td>\n",
       "      <td>Does blocking someone from Instagram cause the...</td>\n",
       "      <td>If someone blocks me on Instagram can they sti...</td>\n",
       "      <td>0</td>\n",
       "      <td>[13.570038013160229, 20.701649758964777, -44.8...</td>\n",
       "      <td>[7.011820152401924, 18.275503396987915, -34.28...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    qid1    qid2  \\\n",
       "70000  70000  120726  120727   \n",
       "70001  70001  120728  120729   \n",
       "70002  70002  120730  120731   \n",
       "70003  70003  120732  120733   \n",
       "70004  70004   31392  120734   \n",
       "\n",
       "                                               question1  \\\n",
       "70000           What are some cake ideas for a teenager?   \n",
       "70001  Is there any encryption technique that cannot ...   \n",
       "70002       Could Napoleon have won the Napoleonic Wars?   \n",
       "70003      Is there an Airbnb for car-sharing in Canada?   \n",
       "70004  Does blocking someone from Instagram cause the...   \n",
       "\n",
       "                                               question2  is_duplicate  \\\n",
       "70000                  What are some teenage cake ideas?             1   \n",
       "70001  How long does it take for a quantum computer t...             0   \n",
       "70002             How could Napoleon have won in Russia?             0   \n",
       "70003                Is there an Airbnb for car-sharing?             0   \n",
       "70004  If someone blocks me on Instagram can they sti...             0   \n",
       "\n",
       "                                              q1_feats_m  \\\n",
       "70000  [-0.4615742415189743, 5.592962011694908, -5.16...   \n",
       "70001  [-9.322475790977478, 12.87209065258503, -7.112...   \n",
       "70002  [-7.683586522936821, 2.8382886052131653, 11.72...   \n",
       "70003  [-0.028497308492660522, 8.290659457445145, -6....   \n",
       "70004  [13.570038013160229, 20.701649758964777, -44.8...   \n",
       "\n",
       "                                              q2_feats_m  \n",
       "70000  [-1.6438209861516953, 2.9957278221845627, -5.0...  \n",
       "70001  [1.2852164027281106, 12.787952169775963, -4.96...  \n",
       "70002  [-7.846307143568993, 8.699695736169815, 4.4572...  \n",
       "70003  [3.1676465570926666, 6.498601824045181, -5.305...  \n",
       "70004  [7.011820152401924, 18.275503396987915, -34.28...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 70000 to 99999\n",
      "Data columns (total 6 columns):\n",
      "id              30000 non-null int64\n",
      "qid1            30000 non-null int64\n",
      "qid2            30000 non-null int64\n",
      "question1       30000 non-null object\n",
      "question2       30000 non-null object\n",
      "is_duplicate    30000 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions_tr = list(df_train['question1']) + list(df_train['question2'])\n",
    "questions_te = list(df_test['question1']) + list(df_test['question2'])\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions_tr)\n",
    "\n",
    "tfidf.transform(questions_te)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFS6m8z5dMUz",
    "outputId": "3c4fb6fd-7f86-4955-8b8f-762b5969ecce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816d0cb7894440b4aa386d38a1ecb324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# en_vectors_web_lg, which includes over 1 million unique vectors.\n",
    "nlp = spacy.load('en_vectors_web_lg')\n",
    "\n",
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df_train['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df_train['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62GEF-RbdMVB",
    "outputId": "60a4f5f8-5582-4886-befd-2ab6ed99c753"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd1ab90749140d4b7640d474196605a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=70000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df_train['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df_train['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4bd8ed2db647778d8f8d08ef82d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vecs1 = []\n",
    "# https://github.com/noamraph/tqdm\n",
    "# tqdm is used to print the progress bar\n",
    "for qu1 in tqdm(list(df_test['question1'])):\n",
    "    doc1 = nlp(qu1) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec1 = np.zeros([len(doc1), len(doc1[0].vector)])\n",
    "    for word1 in doc1:\n",
    "        # word2vec\n",
    "        vec1 = word1.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec1 += vec1 * idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df_test['q1_feats_m'] = list(vecs1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0152fd5948c64bf287d5348431b1c2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df_test['question2'])):\n",
    "    doc2 = nlp(qu2) \n",
    "    mean_vec2 = np.zeros([len(doc2), len(doc2[0].vector)])\n",
    "    for word2 in doc2:\n",
    "        # word2vec\n",
    "        vec2 = word2.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            #print word\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec2 += vec2 * idf\n",
    "    mean_vec2 = mean_vec2.mean(axis=0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df_test['q2_feats_m'] = list(vecs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "\n",
    "df3_train = df_train.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_test = df_test.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "\n",
    "df3_q1_train = pd.DataFrame(df3_train.q1_feats_m.values.tolist(), index= df3_train.index)\n",
    "df3_q2_train = pd.DataFrame(df3_train.q2_feats_m.values.tolist(), index= df3_train.index)\n",
    "\n",
    "df3_q1_test = pd.DataFrame(df3_test.q1_feats_m.values.tolist(), index= df3_test.index)\n",
    "df3_q2_test = pd.DataFrame(df3_test.q2_feats_m.values.tolist(), index= df3_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_train = df1[:70000]\n",
    "df1_test = df1[70000:100000]\n",
    "\n",
    "df2_train = df2[:70000]\n",
    "df2_test = df2[70000:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>69995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>96</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>69996</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>94</td>\n",
       "      <td>84</td>\n",
       "      <td>81</td>\n",
       "      <td>78</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>69997</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.555549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>69998</td>\n",
       "      <td>0</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>48</td>\n",
       "      <td>59</td>\n",
       "      <td>0.216216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>69999</td>\n",
       "      <td>1</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.857131</td>\n",
       "      <td>0.666659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>92</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "69995  69995             1  0.999950  0.666644  0.749981  0.749981  0.833319   \n",
       "69996  69996             1  0.666644  0.499988  0.999975  0.799984  0.857131   \n",
       "69997  69997             0  0.333322  0.249994  0.799984  0.799984  0.624992   \n",
       "69998  69998             0  0.499988  0.399992  0.000000  0.000000  0.399992   \n",
       "69999  69999             1  0.749981  0.749981  0.999967  0.599988  0.857131   \n",
       "\n",
       "        ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "69995  0.714276           0.0            1.0           1.0       6.5   \n",
       "69996  0.666659           1.0            1.0           2.0       8.0   \n",
       "69997  0.555549           0.0            1.0           1.0       8.5   \n",
       "69998  0.249997           0.0            0.0           3.0       6.5   \n",
       "69999  0.666659           0.0            1.0           2.0       8.0   \n",
       "\n",
       "       token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "69995               96                84          88                  93   \n",
       "69996               94                84          81                  78   \n",
       "69997               78                68          76                  76   \n",
       "69998               44                35          48                  59   \n",
       "69999               92                78          83                  84   \n",
       "\n",
       "       longest_substr_ratio  \n",
       "69995              0.580645  \n",
       "69996              0.324324  \n",
       "69997              0.565217  \n",
       "69998              0.216216  \n",
       "69999              0.545455  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>68</td>\n",
       "      <td>76</td>\n",
       "      <td>0.411765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.133332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0.220779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>77</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>66</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>100</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>70004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>0.122642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "70000  70000             1  0.666644  0.666644  0.999967  0.599988  0.833319   \n",
       "70001  70001             0  0.399992  0.249997  0.000000  0.000000  0.153845   \n",
       "70002  70002             0  0.666644  0.499988  0.666644  0.499988  0.571420   \n",
       "70003  70003             0  0.999967  0.749981  0.999975  0.799984  0.999986   \n",
       "70004  70004             0  0.249997  0.249997  0.142855  0.083333  0.187499   \n",
       "\n",
       "        ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "70000  0.624992           0.0            1.0           2.0       7.0   \n",
       "70001  0.133332           0.0            0.0           2.0      14.0   \n",
       "70002  0.571420           0.0            0.0           0.0       7.0   \n",
       "70003  0.777769           0.0            1.0           2.0       8.0   \n",
       "70004  0.124999           0.0            0.0           8.0      20.0   \n",
       "\n",
       "       token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "70000               90                90          68                  76   \n",
       "70001               59                59          30                  43   \n",
       "70002               77                70          65                  66   \n",
       "70003              100                87          87                 100   \n",
       "70004               52                45          43                  46   \n",
       "\n",
       "       longest_substr_ratio  \n",
       "70000              0.411765  \n",
       "70001              0.220779  \n",
       "70002              0.615385  \n",
       "70003              0.972222  \n",
       "70004              0.122642  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 3 columns):\n",
      "id            70000 non-null int64\n",
      "q1_feats_m    70000 non-null object\n",
      "q2_feats_m    70000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df3_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.5</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "      <td>66</td>\n",
       "      <td>75</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>28</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>67</td>\n",
       "      <td>47</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>0.175000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.466664           0.0            1.0           5.0      12.5   \n",
       "2  0.285712           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           2.0      12.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                93          93                 100   \n",
       "1               86                63          66                  75   \n",
       "2               63                63          43                  47   \n",
       "3               28                24           9                  14   \n",
       "4               67                47          35                  56   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982759  \n",
       "1              0.596154  \n",
       "2              0.166667  \n",
       "3              0.039216  \n",
       "4              0.175000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Columns: 300 entries, 0 to 299\n",
      "dtypes: float64(300)\n",
      "memory usage: 160.2 MB\n"
     ]
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df3_q1_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1YIPtTwdMWC",
    "outputId": "510f4c73-0706-4633-d706-e0d348ebfa71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.678341</td>\n",
       "      <td>17.530854</td>\n",
       "      <td>4.767729</td>\n",
       "      <td>8.021592</td>\n",
       "      <td>20.284790</td>\n",
       "      <td>-5.498321</td>\n",
       "      <td>-4.154142</td>\n",
       "      <td>-2.753028</td>\n",
       "      <td>8.035586</td>\n",
       "      <td>146.820392</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.296842</td>\n",
       "      <td>5.405489</td>\n",
       "      <td>0.447179</td>\n",
       "      <td>-8.398855</td>\n",
       "      <td>-1.906411</td>\n",
       "      <td>-10.775995</td>\n",
       "      <td>-13.011710</td>\n",
       "      <td>3.356182</td>\n",
       "      <td>1.184709</td>\n",
       "      <td>16.789048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.467263</td>\n",
       "      <td>13.023918</td>\n",
       "      <td>18.441372</td>\n",
       "      <td>-2.253075</td>\n",
       "      <td>-14.933545</td>\n",
       "      <td>-1.905144</td>\n",
       "      <td>9.034039</td>\n",
       "      <td>-19.527934</td>\n",
       "      <td>-20.590989</td>\n",
       "      <td>16.727846</td>\n",
       "      <td>...</td>\n",
       "      <td>24.319270</td>\n",
       "      <td>1.361967</td>\n",
       "      <td>-9.898601</td>\n",
       "      <td>5.905469</td>\n",
       "      <td>29.164173</td>\n",
       "      <td>3.705868</td>\n",
       "      <td>-28.096061</td>\n",
       "      <td>11.905772</td>\n",
       "      <td>-7.571094</td>\n",
       "      <td>30.854839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.013088</td>\n",
       "      <td>16.138956</td>\n",
       "      <td>-8.150289</td>\n",
       "      <td>-4.897168</td>\n",
       "      <td>-2.783187</td>\n",
       "      <td>9.813789</td>\n",
       "      <td>4.432029</td>\n",
       "      <td>-5.168837</td>\n",
       "      <td>6.834084</td>\n",
       "      <td>106.687464</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.057970</td>\n",
       "      <td>2.404339</td>\n",
       "      <td>8.692217</td>\n",
       "      <td>-0.670134</td>\n",
       "      <td>16.342391</td>\n",
       "      <td>-2.727455</td>\n",
       "      <td>10.608536</td>\n",
       "      <td>-1.088184</td>\n",
       "      <td>-7.383166</td>\n",
       "      <td>19.400510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.963022</td>\n",
       "      <td>17.058119</td>\n",
       "      <td>-15.398349</td>\n",
       "      <td>1.018699</td>\n",
       "      <td>-2.385775</td>\n",
       "      <td>-0.009750</td>\n",
       "      <td>2.653501</td>\n",
       "      <td>-8.421146</td>\n",
       "      <td>2.516107</td>\n",
       "      <td>115.509200</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.582448</td>\n",
       "      <td>-4.883153</td>\n",
       "      <td>-0.462400</td>\n",
       "      <td>-1.942324</td>\n",
       "      <td>9.304168</td>\n",
       "      <td>2.510558</td>\n",
       "      <td>4.764632</td>\n",
       "      <td>-1.218335</td>\n",
       "      <td>-2.840903</td>\n",
       "      <td>3.268202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.125062</td>\n",
       "      <td>19.905821</td>\n",
       "      <td>-4.093182</td>\n",
       "      <td>-6.196883</td>\n",
       "      <td>-20.805312</td>\n",
       "      <td>32.305036</td>\n",
       "      <td>-30.900851</td>\n",
       "      <td>1.034236</td>\n",
       "      <td>-18.629877</td>\n",
       "      <td>84.868632</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.765291</td>\n",
       "      <td>-5.057371</td>\n",
       "      <td>18.897644</td>\n",
       "      <td>-39.186044</td>\n",
       "      <td>-11.491373</td>\n",
       "      <td>16.013101</td>\n",
       "      <td>-0.691998</td>\n",
       "      <td>-10.030701</td>\n",
       "      <td>-7.658805</td>\n",
       "      <td>23.307218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2         3          4          5          6    \\\n",
       "0  -5.678341  17.530854   4.767729  8.021592  20.284790  -5.498321  -4.154142   \n",
       "1   8.467263  13.023918  18.441372 -2.253075 -14.933545  -1.905144   9.034039   \n",
       "2   1.013088  16.138956  -8.150289 -4.897168  -2.783187   9.813789   4.432029   \n",
       "3  -4.963022  17.058119 -15.398349  1.018699  -2.385775  -0.009750   2.653501   \n",
       "4 -11.125062  19.905821  -4.093182 -6.196883 -20.805312  32.305036 -30.900851   \n",
       "\n",
       "         7          8           9      ...            290       291  \\\n",
       "0  -2.753028   8.035586  146.820392    ...     -17.296842  5.405489   \n",
       "1 -19.527934 -20.590989   16.727846    ...      24.319270  1.361967   \n",
       "2  -5.168837   6.834084  106.687464    ...     -21.057970  2.404339   \n",
       "3  -8.421146   2.516107  115.509200    ...      -2.582448 -4.883153   \n",
       "4   1.034236 -18.629877   84.868632    ...      -8.765291 -5.057371   \n",
       "\n",
       "         292        293        294        295        296        297       298  \\\n",
       "0   0.447179  -8.398855  -1.906411 -10.775995 -13.011710   3.356182  1.184709   \n",
       "1  -9.898601   5.905469  29.164173   3.705868 -28.096061  11.905772 -7.571094   \n",
       "2   8.692217  -0.670134  16.342391  -2.727455  10.608536  -1.088184 -7.383166   \n",
       "3  -0.462400  -1.942324   9.304168   2.510558   4.764632  -1.218335 -2.840903   \n",
       "4  18.897644 -39.186044 -11.491373  16.013101  -0.691998 -10.030701 -7.658805   \n",
       "\n",
       "         299  \n",
       "0  16.789048  \n",
       "1  30.854839  \n",
       "2  19.400510  \n",
       "3   3.268202  \n",
       "4  23.307218  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUMdkJTNdMWL",
    "outputId": "69e3e256-cbb8-4fe2-aaf2-9088c3868b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>-1.643821</td>\n",
       "      <td>2.995728</td>\n",
       "      <td>-5.013487</td>\n",
       "      <td>-2.060495</td>\n",
       "      <td>-4.748236</td>\n",
       "      <td>-0.059067</td>\n",
       "      <td>0.270084</td>\n",
       "      <td>-0.296805</td>\n",
       "      <td>7.277772</td>\n",
       "      <td>74.438575</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.741593</td>\n",
       "      <td>2.559344</td>\n",
       "      <td>2.473485</td>\n",
       "      <td>5.224206</td>\n",
       "      <td>1.262848</td>\n",
       "      <td>-0.200858</td>\n",
       "      <td>-0.114223</td>\n",
       "      <td>-8.311147</td>\n",
       "      <td>-1.291231</td>\n",
       "      <td>11.202477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70001</th>\n",
       "      <td>1.285216</td>\n",
       "      <td>12.787952</td>\n",
       "      <td>-4.969135</td>\n",
       "      <td>0.150222</td>\n",
       "      <td>-3.255234</td>\n",
       "      <td>2.345234</td>\n",
       "      <td>-5.966830</td>\n",
       "      <td>-10.950854</td>\n",
       "      <td>17.399258</td>\n",
       "      <td>100.461091</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.123961</td>\n",
       "      <td>-1.360150</td>\n",
       "      <td>1.909143</td>\n",
       "      <td>5.457284</td>\n",
       "      <td>14.133374</td>\n",
       "      <td>-0.290380</td>\n",
       "      <td>12.521746</td>\n",
       "      <td>10.041966</td>\n",
       "      <td>6.579004</td>\n",
       "      <td>10.977388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70002</th>\n",
       "      <td>-7.846307</td>\n",
       "      <td>8.699696</td>\n",
       "      <td>4.457276</td>\n",
       "      <td>-4.747743</td>\n",
       "      <td>-0.247509</td>\n",
       "      <td>-6.322785</td>\n",
       "      <td>2.589292</td>\n",
       "      <td>-5.029269</td>\n",
       "      <td>6.655110</td>\n",
       "      <td>60.201506</td>\n",
       "      <td>...</td>\n",
       "      <td>3.280515</td>\n",
       "      <td>7.250862</td>\n",
       "      <td>0.633417</td>\n",
       "      <td>-4.662525</td>\n",
       "      <td>6.930059</td>\n",
       "      <td>4.226840</td>\n",
       "      <td>4.836946</td>\n",
       "      <td>-0.071511</td>\n",
       "      <td>10.726589</td>\n",
       "      <td>5.850212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70003</th>\n",
       "      <td>3.167647</td>\n",
       "      <td>6.498602</td>\n",
       "      <td>-5.305903</td>\n",
       "      <td>4.210617</td>\n",
       "      <td>-4.383907</td>\n",
       "      <td>2.274286</td>\n",
       "      <td>5.446064</td>\n",
       "      <td>-10.008556</td>\n",
       "      <td>5.603269</td>\n",
       "      <td>63.488409</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.448545</td>\n",
       "      <td>-2.950056</td>\n",
       "      <td>4.594756</td>\n",
       "      <td>-3.209882</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>-2.831094</td>\n",
       "      <td>-2.406799</td>\n",
       "      <td>3.791670</td>\n",
       "      <td>-3.150036</td>\n",
       "      <td>9.444092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70004</th>\n",
       "      <td>7.011820</td>\n",
       "      <td>18.275503</td>\n",
       "      <td>-34.282401</td>\n",
       "      <td>-0.149382</td>\n",
       "      <td>6.029610</td>\n",
       "      <td>-0.932729</td>\n",
       "      <td>-8.865124</td>\n",
       "      <td>-11.803554</td>\n",
       "      <td>-4.607860</td>\n",
       "      <td>258.660846</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.967697</td>\n",
       "      <td>0.102033</td>\n",
       "      <td>8.013830</td>\n",
       "      <td>16.572992</td>\n",
       "      <td>14.287454</td>\n",
       "      <td>-7.044630</td>\n",
       "      <td>-13.224762</td>\n",
       "      <td>-14.174832</td>\n",
       "      <td>13.657328</td>\n",
       "      <td>21.714777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2         3         4         5         6    \\\n",
       "70000 -1.643821   2.995728  -5.013487 -2.060495 -4.748236 -0.059067  0.270084   \n",
       "70001  1.285216  12.787952  -4.969135  0.150222 -3.255234  2.345234 -5.966830   \n",
       "70002 -7.846307   8.699696   4.457276 -4.747743 -0.247509 -6.322785  2.589292   \n",
       "70003  3.167647   6.498602  -5.305903  4.210617 -4.383907  2.274286  5.446064   \n",
       "70004  7.011820  18.275503 -34.282401 -0.149382  6.029610 -0.932729 -8.865124   \n",
       "\n",
       "             7          8           9      ...            290       291  \\\n",
       "70000  -0.296805   7.277772   74.438575    ...      -7.741593  2.559344   \n",
       "70001 -10.950854  17.399258  100.461091    ...     -14.123961 -1.360150   \n",
       "70002  -5.029269   6.655110   60.201506    ...       3.280515  7.250862   \n",
       "70003 -10.008556   5.603269   63.488409    ...     -10.448545 -2.950056   \n",
       "70004 -11.803554  -4.607860  258.660846    ...     -26.967697  0.102033   \n",
       "\n",
       "            292        293        294       295        296        297  \\\n",
       "70000  2.473485   5.224206   1.262848 -0.200858  -0.114223  -8.311147   \n",
       "70001  1.909143   5.457284  14.133374 -0.290380  12.521746  10.041966   \n",
       "70002  0.633417  -4.662525   6.930059  4.226840   4.836946  -0.071511   \n",
       "70003  4.594756  -3.209882   0.214583 -2.831094  -2.406799   3.791670   \n",
       "70004  8.013830  16.572992  14.287454 -7.044630 -13.224762 -14.174832   \n",
       "\n",
       "             298        299  \n",
       "70000  -1.291231  11.202477  \n",
       "70001   6.579004  10.977388  \n",
       "70002  10.726589   5.850212  \n",
       "70003  -3.150036   9.444092  \n",
       "70004  13.657328  21.714777  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_q1_train['id'] = df1_train['id']\n",
    "df3_q2_train['id'] = df1_train['id']\n",
    "\n",
    "df3_q1_test['id'] = df1_test['id']\n",
    "df3_q2_test['id'] = df2_test['id']\n",
    "\n",
    "\n",
    "df1_train = df1_train.merge(df2_train , on = 'id' , how = 'left')\n",
    "df2_train = df3_q1_train.merge(df3_q2_train , on= 'id', how = 'left')\n",
    "train_data = df1_train.merge(df2_train, on= 'id', how='left')\n",
    "\n",
    "\n",
    "df1_test = df1_test.merge(df2_test , on = 'id' , how = 'left')\n",
    "df2_test = df3_q1_test.merge(df3_q2_test , on= 'id', how = 'left')\n",
    "test_data = df1_test.merge(df2_test, on= 'id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>290_y</th>\n",
       "      <th>291_y</th>\n",
       "      <th>292_y</th>\n",
       "      <th>293_y</th>\n",
       "      <th>294_y</th>\n",
       "      <th>295_y</th>\n",
       "      <th>296_y</th>\n",
       "      <th>297_y</th>\n",
       "      <th>298_y</th>\n",
       "      <th>299_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.722322</td>\n",
       "      <td>7.210848</td>\n",
       "      <td>1.560627</td>\n",
       "      <td>-7.553982</td>\n",
       "      <td>0.413443</td>\n",
       "      <td>-11.831222</td>\n",
       "      <td>-11.320478</td>\n",
       "      <td>2.014848</td>\n",
       "      <td>3.508343</td>\n",
       "      <td>12.031769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.699993</td>\n",
       "      <td>0.466664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.603077</td>\n",
       "      <td>3.816482</td>\n",
       "      <td>-4.637692</td>\n",
       "      <td>6.751429</td>\n",
       "      <td>32.837261</td>\n",
       "      <td>6.008906</td>\n",
       "      <td>-26.927030</td>\n",
       "      <td>12.199380</td>\n",
       "      <td>-4.311462</td>\n",
       "      <td>32.635382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.362199</td>\n",
       "      <td>-1.257603</td>\n",
       "      <td>11.921908</td>\n",
       "      <td>9.668108</td>\n",
       "      <td>11.891763</td>\n",
       "      <td>1.331647</td>\n",
       "      <td>6.606182</td>\n",
       "      <td>-0.184381</td>\n",
       "      <td>-12.663971</td>\n",
       "      <td>27.797133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.391686</td>\n",
       "      <td>1.662087</td>\n",
       "      <td>-0.781292</td>\n",
       "      <td>-2.849823</td>\n",
       "      <td>-3.527011</td>\n",
       "      <td>-3.707292</td>\n",
       "      <td>-4.192988</td>\n",
       "      <td>-12.482117</td>\n",
       "      <td>4.452041</td>\n",
       "      <td>-6.207533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.436148</td>\n",
       "      <td>-8.375029</td>\n",
       "      <td>-14.418071</td>\n",
       "      <td>-12.666133</td>\n",
       "      <td>-4.445768</td>\n",
       "      <td>12.530975</td>\n",
       "      <td>-11.736673</td>\n",
       "      <td>-16.401188</td>\n",
       "      <td>3.687729</td>\n",
       "      <td>-9.810974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.799984  0.399996  0.749981  0.599988  0.699993   \n",
       "2   2             0  0.399992  0.333328  0.399992  0.249997  0.399996   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq    ...          290_y     291_y  \\\n",
       "0  0.785709           0.0            1.0    ...     -17.722322  7.210848   \n",
       "1  0.466664           0.0            1.0    ...      21.603077  3.816482   \n",
       "2  0.285712           0.0            1.0    ...     -24.362199 -1.257603   \n",
       "3  0.000000           0.0            0.0    ...      -5.391686  1.662087   \n",
       "4  0.307690           0.0            1.0    ...     -10.436148 -8.375029   \n",
       "\n",
       "       292_y      293_y      294_y      295_y      296_y      297_y  \\\n",
       "0   1.560627  -7.553982   0.413443 -11.831222 -11.320478   2.014848   \n",
       "1  -4.637692   6.751429  32.837261   6.008906 -26.927030  12.199380   \n",
       "2  11.921908   9.668108  11.891763   1.331647   6.606182  -0.184381   \n",
       "3  -0.781292  -2.849823  -3.527011  -3.707292  -4.192988 -12.482117   \n",
       "4 -14.418071 -12.666133  -4.445768  12.530975 -11.736673 -16.401188   \n",
       "\n",
       "       298_y      299_y  \n",
       "0   3.508343  12.031769  \n",
       "1  -4.311462  32.635382  \n",
       "2 -12.663971  27.797133  \n",
       "3   4.452041  -6.207533  \n",
       "4   3.687729  -9.810974  \n",
       "\n",
       "[5 rows x 628 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>290_y</th>\n",
       "      <th>291_y</th>\n",
       "      <th>292_y</th>\n",
       "      <th>293_y</th>\n",
       "      <th>294_y</th>\n",
       "      <th>295_y</th>\n",
       "      <th>296_y</th>\n",
       "      <th>297_y</th>\n",
       "      <th>298_y</th>\n",
       "      <th>299_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.624992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.741593</td>\n",
       "      <td>2.559344</td>\n",
       "      <td>2.473485</td>\n",
       "      <td>5.224206</td>\n",
       "      <td>1.262848</td>\n",
       "      <td>-0.200858</td>\n",
       "      <td>-0.114223</td>\n",
       "      <td>-8.311147</td>\n",
       "      <td>-1.291231</td>\n",
       "      <td>11.202477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.133332</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.123961</td>\n",
       "      <td>-1.360150</td>\n",
       "      <td>1.909143</td>\n",
       "      <td>5.457284</td>\n",
       "      <td>14.133374</td>\n",
       "      <td>-0.290380</td>\n",
       "      <td>12.521746</td>\n",
       "      <td>10.041966</td>\n",
       "      <td>6.579004</td>\n",
       "      <td>10.977388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.280515</td>\n",
       "      <td>7.250862</td>\n",
       "      <td>0.633417</td>\n",
       "      <td>-4.662525</td>\n",
       "      <td>6.930059</td>\n",
       "      <td>4.226840</td>\n",
       "      <td>4.836946</td>\n",
       "      <td>-0.071511</td>\n",
       "      <td>10.726589</td>\n",
       "      <td>5.850212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.749981</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>0.799984</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.777769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.448545</td>\n",
       "      <td>-2.950056</td>\n",
       "      <td>4.594756</td>\n",
       "      <td>-3.209882</td>\n",
       "      <td>0.214583</td>\n",
       "      <td>-2.831094</td>\n",
       "      <td>-2.406799</td>\n",
       "      <td>3.791670</td>\n",
       "      <td>-3.150036</td>\n",
       "      <td>9.444092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70004</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.187499</td>\n",
       "      <td>0.124999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.967697</td>\n",
       "      <td>0.102033</td>\n",
       "      <td>8.013830</td>\n",
       "      <td>16.572992</td>\n",
       "      <td>14.287454</td>\n",
       "      <td>-7.044630</td>\n",
       "      <td>-13.224762</td>\n",
       "      <td>-14.174832</td>\n",
       "      <td>13.657328</td>\n",
       "      <td>21.714777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 628 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0  70000             1  0.666644  0.666644  0.999967  0.599988  0.833319   \n",
       "1  70001             0  0.399992  0.249997  0.000000  0.000000  0.153845   \n",
       "2  70002             0  0.666644  0.499988  0.666644  0.499988  0.571420   \n",
       "3  70003             0  0.999967  0.749981  0.999975  0.799984  0.999986   \n",
       "4  70004             0  0.249997  0.249997  0.142855  0.083333  0.187499   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq    ...          290_y     291_y  \\\n",
       "0  0.624992           0.0            1.0    ...      -7.741593  2.559344   \n",
       "1  0.133332           0.0            0.0    ...     -14.123961 -1.360150   \n",
       "2  0.571420           0.0            0.0    ...       3.280515  7.250862   \n",
       "3  0.777769           0.0            1.0    ...     -10.448545 -2.950056   \n",
       "4  0.124999           0.0            0.0    ...     -26.967697  0.102033   \n",
       "\n",
       "      292_y      293_y      294_y     295_y      296_y      297_y      298_y  \\\n",
       "0  2.473485   5.224206   1.262848 -0.200858  -0.114223  -8.311147  -1.291231   \n",
       "1  1.909143   5.457284  14.133374 -0.290380  12.521746  10.041966   6.579004   \n",
       "2  0.633417  -4.662525   6.930059  4.226840   4.836946  -0.071511  10.726589   \n",
       "3  4.594756  -3.209882   0.214583 -2.831094  -2.406799   3.791670  -3.150036   \n",
       "4  8.013830  16.572992  14.287454 -7.044630 -13.224762 -14.174832  13.657328   \n",
       "\n",
       "       299_y  \n",
       "0  11.202477  \n",
       "1  10.977388  \n",
       "2   5.850212  \n",
       "3   9.444092  \n",
       "4  21.714777  \n",
       "\n",
       "[5 rows x 628 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('final_jun24_train.csv', sep=';')\n",
    "test_data.to_csv('final_jun24_test.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['is_duplicate']\n",
    "train_data = train_data.drop(['id', 'is_duplicate'],axis=1)\n",
    "X_train = train_data.iloc[:,:].values\n",
    "\n",
    "\n",
    "y_test = test_data['is_duplicate']\n",
    "test_data = test_data.drop(['id', 'is_duplicate'],axis=1)\n",
    "X_test = test_data.iloc[:,:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 626), (70000,), (30000, 626), (30000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , y_train.shape , X_test.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.6275428571428572 Class 1:  0.3724571428571429\n",
      "---------- Distribution of output variable in train data ----------\n",
      "Class 0:  0.37273333333333336 Class 1:  0.37273333333333336\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "train_distr = Counter(y_train)\n",
    "train_len = len(y_train)\n",
    "print(\"Class 0: \",int(train_distr[0])/train_len,\"Class 1: \", int(train_distr[1])/train_len)\n",
    "print(\"-\"*10, \"Distribution of output variable in train data\", \"-\"*10)\n",
    "test_distr = Counter(y_test)\n",
    "test_len = len(y_test)\n",
    "print(\"Class 0: \",int(test_distr[1])/test_len, \"Class 1: \",int(test_distr[1])/test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.4 Building a random model (Finding worst-case log-loss) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss on Test Data using Random Model 0.8816597149250973\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we need to generate 9 numbers and the sum of numbers should be 1\n",
    "# one solution is to genarate 9 numbers and divide each of the numbers by their sum\n",
    "# ref: https://stackoverflow.com/a/18662466/4084039\n",
    "# we create a output array that has exactly same size as the CV data\n",
    "predicted_y = np.zeros((test_len,2))\n",
    "for i in range(test_len):\n",
    "    rand_probs = np.random.rand(1,2)\n",
    "    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "print(\"Log loss on Test Data using Random Model\",log_loss(y_test, predicted_y, eps=1e-15))\n",
    "\n",
    "predicted_y =np.argmax(predicted_y, axis=1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.6 XGBoost </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.06618101782710437, max_depth=3, n_estimators=81 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.06618101782710437, max_depth=3, n_estimators=81, score=0.8107428571428571, total= 2.3min\n",
      "[CV] learning_rate=0.06618101782710437, max_depth=3, n_estimators=81 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.06618101782710437, max_depth=3, n_estimators=81, score=0.8082, total= 2.5min\n",
      "[CV] learning_rate=0.11979909127171076, max_depth=3, n_estimators=61 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.11979909127171076, max_depth=3, n_estimators=61, score=0.8156571428571429, total= 2.1min\n",
      "[CV] learning_rate=0.11979909127171076, max_depth=3, n_estimators=61 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  6.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.11979909127171076, max_depth=3, n_estimators=61, score=0.8122571428571429, total= 2.0min\n",
      "[CV] learning_rate=0.033402796066365474, max_depth=5, n_estimators=81 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  8.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.033402796066365474, max_depth=5, n_estimators=81, score=0.8159714285714286, total= 4.0min\n",
      "[CV] learning_rate=0.033402796066365474, max_depth=5, n_estimators=81 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.033402796066365474, max_depth=5, n_estimators=81, score=0.8134, total= 3.9min\n",
      "[CV] learning_rate=0.01871254182522992, max_depth=3, n_estimators=91 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 16.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01871254182522992, max_depth=3, n_estimators=91, score=0.7947142857142857, total= 2.6min\n",
      "[CV] learning_rate=0.01871254182522992, max_depth=3, n_estimators=91 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 19.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01871254182522992, max_depth=3, n_estimators=91, score=0.7928, total= 2.7min\n",
      "[CV] learning_rate=0.031430022688291114, max_depth=5, n_estimators=71 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 22.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.031430022688291114, max_depth=5, n_estimators=71, score=0.8153428571428571, total= 3.5min\n",
      "[CV] learning_rate=0.031430022688291114, max_depth=5, n_estimators=71 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 25.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.031430022688291114, max_depth=5, n_estimators=71, score=0.8111714285714285, total= 3.5min\n",
      "[CV] learning_rate=0.01846173685406504, max_depth=4, n_estimators=71 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 29.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01846173685406504, max_depth=4, n_estimators=71, score=0.8013142857142858, total= 2.7min\n",
      "[CV] learning_rate=0.01846173685406504, max_depth=4, n_estimators=71 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed: 31.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01846173685406504, max_depth=4, n_estimators=71, score=0.7993142857142858, total= 2.9min\n",
      "[CV] learning_rate=0.010116814876152149, max_depth=3, n_estimators=61 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed: 34.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.010116814876152149, max_depth=3, n_estimators=61, score=0.7883428571428571, total= 1.8min\n",
      "[CV] learning_rate=0.010116814876152149, max_depth=3, n_estimators=61 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed: 36.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.010116814876152149, max_depth=3, n_estimators=61, score=0.7832, total= 1.8min\n",
      "[CV] learning_rate=0.05563633644393066, max_depth=4, n_estimators=61 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed: 38.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.05563633644393066, max_depth=4, n_estimators=61, score=0.8133142857142858, total= 2.4min\n",
      "[CV] learning_rate=0.05563633644393066, max_depth=4, n_estimators=61 .\n",
      "[CV]  learning_rate=0.05563633644393066, max_depth=4, n_estimators=61, score=0.8095142857142857, total= 2.4min\n",
      "[CV] learning_rate=0.07479175279631736, max_depth=3, n_estimators=81 .\n",
      "[CV]  learning_rate=0.07479175279631736, max_depth=3, n_estimators=81, score=0.8136, total= 2.4min\n",
      "[CV] learning_rate=0.07479175279631736, max_depth=3, n_estimators=81 .\n",
      "[CV]  learning_rate=0.07479175279631736, max_depth=3, n_estimators=81, score=0.8098285714285715, total= 2.8min\n",
      "[CV] learning_rate=0.10177793420835692, max_depth=4, n_estimators=91 .\n",
      "[CV]  learning_rate=0.10177793420835692, max_depth=4, n_estimators=91, score=0.8268285714285715, total= 3.9min\n",
      "[CV] learning_rate=0.10177793420835692, max_depth=4, n_estimators=91 .\n",
      "[CV]  learning_rate=0.10177793420835692, max_depth=4, n_estimators=91, score=0.8224285714285714, total= 3.7min\n",
      "[CV] learning_rate=0.05382169728028272, max_depth=5, n_estimators=71 .\n",
      "[CV]  learning_rate=0.05382169728028272, max_depth=5, n_estimators=71, score=0.8205142857142858, total= 4.0min\n",
      "[CV] learning_rate=0.05382169728028272, max_depth=5, n_estimators=71 .\n",
      "[CV]  learning_rate=0.05382169728028272, max_depth=5, n_estimators=71, score=0.8174571428571429, total= 3.5min\n",
      "[CV] learning_rate=0.02359096517992312, max_depth=4, n_estimators=81 .\n",
      "[CV]  learning_rate=0.02359096517992312, max_depth=4, n_estimators=81, score=0.8054571428571429, total= 3.4min\n",
      "[CV] learning_rate=0.02359096517992312, max_depth=4, n_estimators=81 .\n",
      "[CV]  learning_rate=0.02359096517992312, max_depth=4, n_estimators=81, score=0.8035714285714286, total= 3.3min\n",
      "[CV] learning_rate=0.06736929869007441, max_depth=3, n_estimators=81 .\n",
      "[CV]  learning_rate=0.06736929869007441, max_depth=3, n_estimators=81, score=0.8118, total= 2.4min\n",
      "[CV] learning_rate=0.06736929869007441, max_depth=3, n_estimators=81 .\n",
      "[CV]  learning_rate=0.06736929869007441, max_depth=3, n_estimators=81, score=0.8083714285714285, total= 2.4min\n",
      "[CV] learning_rate=0.13899106101044809, max_depth=5, n_estimators=61 .\n",
      "[CV]  learning_rate=0.13899106101044809, max_depth=5, n_estimators=61, score=0.8293428571428572, total= 3.3min\n",
      "[CV] learning_rate=0.13899106101044809, max_depth=5, n_estimators=61 .\n",
      "[CV]  learning_rate=0.13899106101044809, max_depth=5, n_estimators=61, score=0.8265428571428571, total= 3.1min\n",
      "[CV] learning_rate=0.07757488779543144, max_depth=4, n_estimators=91 .\n",
      "[CV]  learning_rate=0.07757488779543144, max_depth=4, n_estimators=91, score=0.8241142857142857, total= 3.7min\n",
      "[CV] learning_rate=0.07757488779543144, max_depth=4, n_estimators=91 .\n",
      "[CV]  learning_rate=0.07757488779543144, max_depth=4, n_estimators=91, score=0.8195714285714286, total= 3.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 89.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, early_stopping_rounds=10, eval_metric='logloss',\n",
      "       gamma=0, learning_rate=0.13899106101044809, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=1, missing=None, n_estimators=61,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier as xgbc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "\n",
    "clf = xgbc(objective = 'binary:logistic',eval_metric = 'logloss',  early_stopping_rounds= 10)\n",
    "\n",
    "tuned_param = {\n",
    "\n",
    "        'max_depth': [3,4,5],\n",
    "        'learning_rate': stats.uniform(0.01,0.15),       \n",
    "        'n_estimators': [x for x in range(61,101,10) ]\n",
    "    \n",
    "        }\n",
    "\n",
    "\n",
    "model = RandomizedSearchCV(clf, tuned_param, n_iter=15, verbose=15, cv=2,random_state=42)\n",
    "\n",
    "model.fit(X_train , y_train)\n",
    "\n",
    "print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, early_stopping_rounds=10, eval_metric='logloss',\n",
       "       gamma=0, learning_rate=0.13899106101044809, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=61,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test log loss is: 0.34815545727438585\n"
     ]
    }
   ],
   "source": [
    "xgb_best = model.best_estimator_\n",
    "\n",
    "xgb_best.fit(X_train, y_train)\n",
    "\n",
    "predict_y = xgb_best.predict_proba(X_test)\n",
    "\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, labels = [0,1], eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train log loss is: 0.3209566132494947\n"
     ]
    }
   ],
   "source": [
    "predict_y = xgb_best.predict_proba(X_train)\n",
    "print(\"The train log loss is:\",log_loss(y_train, predict_y, labels = [0,1], eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points : 30000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predicted_y =np.array(predict_y[0] >0.5,dtype=int)\n",
    "predicted_y = []\n",
    "\n",
    "for pre in predict_y[:,0]:\n",
    "    if pre > 0.5:\n",
    "        predicted_y.append(0)\n",
    "    else:\n",
    "        predicted_y.append(1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------+---------------------------------------+\n",
      "|   Parameter    | Logistic_reg | L-SVM  |                XGBoost                |\n",
      "+----------------+--------------+--------+---------------------------------------+\n",
      "| hyperparameter |    0.001     | 0.001  | LR=0.138,max_depth=5,n_estimators=61, |\n",
      "| featurization  |    tfidf     | tfidf  |                 avgW2V                |\n",
      "|   train_loss   |    0.3974    | 0.4159 |                 0.348                 |\n",
      "|   test_loss    |    0.4114    | 0.4193 |                 0.320                 |\n",
      "+----------------+--------------+--------+---------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "summ = PrettyTable()\n",
    "\n",
    "column_names = [\"Parameter\", \"Logistic_reg\", \"L-SVM\", \"XGBoost\"]\n",
    "summ.add_column(column_names[0],['hyperparameter' , 'featurization', 'train_loss', 'test_loss'] )\n",
    "summ.add_column(column_names[1], ['0.001','tfidf', '0.3974', '0.4114'])\n",
    "summ.add_column(column_names[2],['0.001','tfidf', '0.4159', '0.4193'] )\n",
    "summ.add_column(column_names[3],['LR=0.138,max_depth=5,n_estimators=61,','avgW2V', '0.348', '0.320'] )\n",
    "\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
